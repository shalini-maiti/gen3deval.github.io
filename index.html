<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A holistic ranking metric to assess the quality of generated 3D objects on appearance, surface quality and text faithfulness using a vision large language model (vLLM) which is trained to choose the better object between a pair on the basis of either appearance, text faithfulness or surface quality.">
  <meta name="keywords" content="Vision Large Language Model, vLLM, text-to-3D, 3D, Generative AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gen3DEval: Using vLLMs for automatic evaluation of generated 3D objects</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script>
    let currentVideoIndex = 0;
    let currentVideoSet = "set1";
    
    function changeVideos() {
      const videoSets = {
        set1: [
          "static/videos/set1/set1_app.mp4", 
          "static/videos/set1/set1_tf.mp4", 
          "static/videos/set1/set1_sq.mp4"
        ],
        set2: [
          "static/videos/set2/set2_app.mp4", 
          "static/videos/set2/set2_tf.mp4", 
          "static/videos/set2/set2_sq.mp4"
        ],
        set3: [
          "static/videos/set3/set3_app.mp4", 
          "static/videos/set3/set3_tf.mp4", 
          "static/videos/set3/set3_sq.mp4"
        ]
      };
      
      currentVideoSet = document.getElementById("videoSelector").value;
      currentVideoIndex = 0;
      
      showCurrentVideo();
    }
    
    function showCurrentVideo() {
      const videoSets = {
        set1: [
          "static/videos/set1/set1_app.mp4", 
          "static/videos/set1/set1_tf.mp4", 
          "static/videos/set1/set1_sq.mp4"
        ],
        set2: [
          "static/videos/set2/set2_app.mp4", 
          "static/videos/set2/set2_tf.mp4", 
          "static/videos/set2/set2_sq.mp4"
        ],
        set3: [
          "static/videos/set3/set3_app.mp4", 
          "static/videos/set3/set3_tf.mp4", 
          "static/videos/set3/set3_sq.mp4"
        ]
      };
      let currentVideo = document.getElementById("currentVideo");
      currentVideo.srcObject = null;
      currentVideo.src = videoSets[currentVideoSet][currentVideoIndex];
      currentVideo.load();
      // let currentVideo = document.getElementById("currentVideo");
      // currentVideo.src = videoSets[currentVideoSet][currentVideoIndex];
      // currentVideo.load();
      let titleText;
      switch (currentVideoIndex) {
        case 0:
          titleText = "Appearance";
          break;
        case 1:
          titleText = "Text Fidelity";
          break;
        case 2:
          titleText = "Surface Quality";
          break;
      }
      
      let titleElement = document.querySelector(".carousel-item.is-active p.title");
      titleElement.textContent = titleText;
    }
    
    function showNextVideo() {
      currentVideoIndex = (currentVideoIndex + 1) % 3;
      showCurrentVideo();
    }
    
    function showPrevVideo() {
      currentVideoIndex = (currentVideoIndex - 1 + 3) % 3;
      showCurrentVideo();
    }
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Gen3DEval: Using vLLMs for automatic evaluation of generated 3D objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/shalini-maiti-a76a2b86/?originalSubdomain=uk">Shalini Maiti</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.ucl.ac.uk/computer-science/people/prof-lourdes-de-agapito-vicente">Lourdes Agapito</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.fkokkinos.com/">Filippos Kokkinos</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Meta AI</span>
            <span class="author-block"><sup>2</sup>University College London</span>
          </div>
          
          <div id="accepted-banner" style="text-align: center; font-size: 24px; font-weight: bold; color: #457b9d; margin-top: 10px;">
            ðŸŽ‰ Accepted to CVPR 2025! ðŸŽ‰
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/05691_main.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="./static/05691_supp.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon!)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Leaderboard Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Leaderboard</span>
                  </a> -->
              <!-- Checkpoint Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Checkpoint</span>
                  </a> -->
              <!-- Checkpoint Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser_video3.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Gen3DEval:</span>  A holistic ranking metric to assess the 
        quality of generated 3D objects on appearance, surface quality and text 
        fidelity using a vision large language model (vLLM) which is trained to 
        choose the better out of two objects on the three evaluation dimensions 
        (appearance, text fidelity or surface quality). 
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/supp_video_compress.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Rapid advancements in text-to-3D generation require robust and 
            scalable evaluation metrics that align closely with human judgment, 
            a need unmet by current metrics such as PSNR and CLIP, which 
            require ground-truth data or focus only on prompt fidelity. 
            To address this, we introduce Gen3DEval, a novel evaluation 
            framework that leverages vision large language models (vLLMs) 
            specifically fine-tuned for 3D object quality assessment. 
            Gen3DEval evaluates text fidelity, appearance, and surface 
            quality by analyzing 3D surface normals, without requiring 
            ground-truth comparisons, bridging the gap between automated 
            metrics and user preferences. Compared to state-of-the-art 
            task-agnostic models, Gen3DEval demonstrates superior 
            performance in user-aligned evaluations, placing it as 
            a comprehensive and accessible benchmark for future 
            research on text-to-3D generation. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview of the Method</h2>
        <div class="image-container" style="display: inline-block; margin: 10px;">
          <img src="./static/images/model_details.png" alt="Image 1" style="width: 100%; height: auto; border-radius: 10px;">
          <p>In stage 1, we train a vLLM to choose which object is better in terms of appearance, 
            surface quality or text fidelity. This is further divided into 2 parts. 
            In pre-training, we train the vision-to-language projector using image 
            summary VQA. In the supervised fine-tuning (SFT) stage, we use comparison 
            data to train for instruction following and preference evaluation. In stage 2, 
            we compute a ranking metric for the set of methods by applying the trained vLLM 
            from stage 1 pairwise on Gen3DEval-Bench prompts.</p>
        </div>
      </div>
    </div>
    <!--/ Paper overview. -->
  </div>

<!--/ Dataset. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Training Dataset</h2>
        <p>We use single and multi-view RGB and surface normals renderings of a 3D object generated from a prompt.
          We take these objects and perturb them to simulate common appearance, surface and text-related artefacts in generative 3D methods.</p>
        <section id="images" style="text-align: center; margin: 20px 0;">
          <div class="image-container" style="display: inline-block; margin: 10px;">
            <h3 class="title is-4">Pre-Training Dataset</h2>
              <img src="./static/images/pre_training_example.png" alt="Image 1" style="width: 100%; height: auto; border-radius: 1px;">
              
          </div>
          <div class="image-container" style="display: inline-block; margin: 10px;">
            <h3 class="title is-4">Supervised FineTuning Dataset</h2>
              <img src="./static/images/sft_examples.png" alt="Image 2" style="width: 100%; height: auto; border-radius: 1px;">
              
          </div>
      </div>
    </div>
  </div>
</section>

<!--/ Benchmark. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmark: Gen3DEval-Bench</h2>
        <!-- <section id="images" style="text-align: center; margin: 20px 0;"> -->
          <p>We create a diverse set of 80 prompts, Gen3DEval-Bench,
            which considers the diversity of objects, textures, and levels
            of composition. We determine the size of this benchmark with 
            the consideration that text-to-3D generation is a
            time- and computation-intensive process, aiming to make
            the benchmark easily accessible. It is split between 40 animate 
            (humanoids, animals) objects and 40 inanimate objects, 
            as well as into 43 single object and 37 composite 
            object prompts, i.e., combining multiple objects. The average
            number of words per prompt is 12.863.</p>
          <div class="image-container" style="display: inline-block; margin: 10px;">
            <!-- <h3 class="title is-4">Comparison with other benchmarks</h2> -->
              <table>
                <thead>
                    <tr>
                        <th>Benchmark</th>
                          <th>Num. Prompts</th>
                          <th>Avg. word length</th>
                          <th>Object Type (Animate)</th>
                          <th>Object Type (Inanimate)</th>
                          <th>Composition (Single Obj.)</th>
                          <th>Composition (Multi-object)</th>
                    </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>T3Bench</td>
                    <td>300</td>
                    <td>7.98</td>
                    <td>36</td>
                    <td>264</td>
                    <td>100</td>
                    <td>200</td>
                  </tr>
                  <tr>
                    <td>ChatGPTEval3D</td>
                    <td>110</td>
                    <td>11.49</td>
                    <td>18</td>
                    <td>92</td>
                    <td>65</td>
                    <td>45</td>
                  </tr>
                  <tr>
                    <td>DreamFusion</td>
                    <td>404</td>
                    <td>6.98</td>
                    <td>211</td>
                    <td>192</td>
                    <td>154</td>
                    <td>250</td>
                  </tr>
                  <tr>
                    <td>Gen3DEval-Bench </td>
                    <td>80</td>
                    <td>12.863</td>
                    <td>40</td>
                    <td>40</td>
                    <td>43</td>
                    <td>37</td>
                  </tr>
                </tbody>
              </table>
              <p><span class="dnerf">Comparing Gen3DEval-Bench</span> with existing 3D generation prompt benchmarks.</p>
              <!-- <img src="./static/images/pre_training_example.png" alt="Image 1" style="width: 100%; height: auto; border-radius: 1px;"> -->
          </div>
          
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Asset Comparison Examples</h2>
          <label for="videoSelector">Choose a text prompt:</label>
          <select id="videoSelector" onchange="changeVideos()">
            <option value="set1">A panda with coarse black and white fur, holding a bamboo shoot with visible teeth marks.</option>
            <option value="set2">A desk organizer with compartments for pens and papers, showing slight scratches on the surface.</option>
            <option value="set3">A human wizard with a long beard, holding a glowing staff, casting a spell.</option>
          </select>
          <div class="carousel" data-carousel-id="videoCarousel">
            <div class="arrow left-arrow" onclick="showPrevVideo()">
              <i class="fas fa-chevron-left"></i>
            </div>
            <div class="carousel-item is-active">
              <p class="title is-4">Appearance</p>
              <video id="currentVideo" width="100%" autoplay muted loop>
                <!-- Current Video -->
                  <source src="static/videos/set1/set1_app.mp4" type="video/mp4">
              </video>
            </div>
            <div class="arrow right-arrow" onclick="showNextVideo()">
              <i class="fas fa-chevron-right"></i>
            </div>
          </div>
          
          <!-- <div class="carousel" data-carousel-id="videoCarousel"> -->
            <!-- <div class="carousel-item is-active"> -->
              <!-- <video id="video1" width="100%" autoplay muted loop> -->
                <!-- Appearance -->
                  <!-- <source src="static/videos/set1/set1_app.mp4" type="video/mp4"> -->
              <!-- </video> -->
            <!-- </div> -->
            <!-- <div class="carousel-item"> -->
              <!-- <video id="video2" width="100%" autoplay muted loop> -->
                <!-- Text Fidelity -->
                  <!-- <source src="static/videos/set1/set1_tf.mp4" type="video/mp4"> -->
              <!-- </video> -->
            <!-- </div> -->
            <!-- <div class="carousel-item"> -->
              <!-- <video id="video3" width="100%" autoplay muted loop> -->
                <!-- Surface Quality -->
                  <!-- <source src="static/videos/set1/set1_sq.mp4" type="video/mp4"> -->
              <!-- </video> -->
            <!-- </div> -->
          <!-- </div> -->
          <!-- <button class="button is-primary" data-carousel-next="videoCarousel">Next</button>
          <button class="button is-primary" data-carousel-prev="videoCarousel">Previous</button> -->
    </div>
  </div>
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Leaderboard Rankings</h2>
        <table>
          <thead>
              <tr>
                  <th>Method</th>
                  <th>Appearance</th>
                  <th>Text Fidelity</th>
                  <th>Overall</th>
              </tr>
          </thead>
          <tbody>
              <script>
                const items = [
                    ["Trellis*", "1", "1", "1"],
                    ["AssetGen", "2", "2", "2"],
                    ["Flex3d*", "4", "3", "3"],
                    ["LatentNerf", "3", "6", "4"],
                    ["Magic123", "5", "4", "5"],
                    ["Vfusion3d*", "6", "5", "6"],
                    ["Magic3d", "7", "7", "7"],
                    ["DreamFusion", "8", "8", "8"],
                    // ["Fantasia3D", "Item 9-2", "Item 9-3", "Item 9-4"],
                    // ["Item 10-1", "Item 10-2", "Item 10-3", "Item 10-4"]
                  ];
                  for (let i = 0; i < items.length; i++) {
                    document.write('<tr>');
                    for (let j = 0; j < items[i].length; j++) {
                      document.write(`<td>${items[i][j]}</td>`);
                    }
                    document.write('</tr>');
                  }
              </script>
          </tbody>
        </table>
        <span class="dnerf">Gen3DEval</span> applied to 3D generation methods on Gen3DEval-Bench. 
        Methods are ranked from Best(1) to Worst(8) on text fidelity and appearance score. 
        The appearance and text fidelity scores are used for the overall score. 
        Image-to-3D methods are denoted with *.
      </div>
    </div>
  </div>
</div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{maiti2025gen3DEval,
        author={Shalini Maiti and Lourdes Agapito and Filippos Kokkinos},
        title={Gen3DEval: Using vLLMs for automatic evaluation of generated 3D objects}, 
        booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year = {2025}
      }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template is adapted from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, under a <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License.</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>